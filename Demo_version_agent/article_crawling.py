import os
import pathlib
import requests
import bs4
import time
import re
from dotenv import load_dotenv
from datetime import datetime, timedelta, timezone
from bs4 import BeautifulSoup
import feedparser


from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_community.document_loaders import WebBaseLoader





load_dotenv()

# --- LANGCHAIN AGENT FUNCTIONS (ìˆ˜ì • ì—†ìŒ) ---
def filter_candidates_by_title(news_list: list, user_profile: dict) -> list:
    # ... (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    print("\nğŸ¤– [1ë‹¨ê³„] AIê°€ ì œëª©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‰´ìŠ¤ í›„ë³´êµ°ì„ í•„í„°ë§í•©ë‹ˆë‹¤...")
    formatted_news_titles = "\n".join([f"{i+1}. {article['title']}" for i, article in enumerate(news_list)])
    prompt = ChatPromptTemplate.from_template("""
     ë‹¹ì‹ ì€ ê²½ì œ ë‰´ìŠ¤ íë ˆì´í„°ì…ë‹ˆë‹¤. [ì‚¬ìš©ì ì •ë³´]ì™€ [ë‰´ìŠ¤ ì œëª© ëª©ë¡]ì„ ë³´ê³ ,
     ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì•„ ë³´ì´ëŠ” ê¸°ì‚¬ 7ê°œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.

     [ë ˆë²¨ ì •ì˜]
     - ì”¨ì•—: ê²½ì œ ìš©ì–´ê°€ ë‚¯ì„  ì™„ì „ ì…ë¬¸ì.
     - ìƒˆì‹¹: ê¸°ë³¸ì ì¸ ê²½ì œ ê°œë…ì„ ë°°ìš°ëŠ” ì´ˆê¸‰ì.
     - ë‚˜ë¬´: ì£¼ìš” ê²½ì œ ì§€í‘œë¥¼ ì´í•´í•˜ëŠ” ì¤‘ê¸‰ì.
     - ìˆ²: ê²½ì œ íë¦„ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ê³ ê¸‰ì.

     [ì‚¬ìš©ì ì •ë³´]
     - ë ˆë²¨: {level}
     - ìµœê·¼ ê´€ì‹¬ì‚¬: {chat_history}

     [ë‰´ìŠ¤ ì œëª© ëª©ë¡]
     {news_titles}

     [ìš”ì²­]
     ê°€ì¥ ì í•©í•œ ê¸°ì‚¬ 7ê°œì˜ ë²ˆí˜¸ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.
     ì˜ˆì‹œ: {{"selected_indices": [3, 8, 15, 2, 9, 1, 11]}}""")
    model = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    parser = JsonOutputParser()
    chain = prompt | model | parser
    try:
        response = chain.invoke({"level": user_profile['level'], "chat_history": ", ".join(user_profile['chat_history']), "news_titles": formatted_news_titles})
        selected_indices = response['selected_indices']
        candidate_news = [news_list[i-1] for i in selected_indices if 0 < i <= len(news_list)]
        print(f"âœ… 1ë‹¨ê³„ í•„í„°ë§ ì™„ë£Œ. í›„ë³´ ë‰´ìŠ¤ {len(candidate_news)}ê±´ ì„ íƒ.")
        return candidate_news
    except Exception as e:
        print(f"ğŸ”´ 1ë‹¨ê³„ AI í•„í„°ë§ ì‹¤íŒ¨: {e}")
        return news_list[:7]

def select_final_articles_by_content(candidate_news: list, user_profile: dict) -> list:
    # ... (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    print("\nğŸ¤– [2ë‹¨ê³„] AIê°€ ìŠ¤í¬ë©í•œ ë³¸ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ë‰´ìŠ¤ë¥¼ ì„ ë³„í•©ë‹ˆë‹¤...")
    formatted_candidates = "\n\n".join([f"ê¸°ì‚¬ #{i+1}:\n- ì œëª©: {article['title']}\n- ë³¸ë¬¸ ì¼ë¶€: {article.get('content', 'ë‚´ìš© ì—†ìŒ')}" for i, article in enumerate(candidate_news)])
    prompt = ChatPromptTemplate.from_template("""ë‹¹ì‹ ì€ ê°œì¸ ë§ì¶¤í˜• ê²½ì œ ë‰´ìŠ¤ íë ˆì´í„°ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê²½ì œ ì§€ì‹ ìˆ˜ì¤€ê³¼ ê´€ì‹¬ì‚¬ë¥¼ ê³ ë ¤í•˜ì—¬, ì•„ë˜ [í›„ë³´ ë‰´ìŠ¤ ëª©ë¡]ì˜ 'ë³¸ë¬¸'ì„ ì½ê³  ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ìœ ìµí•˜ê³  ì¤‘ìš”í•œ ìµœì¢… ê¸°ì‚¬ 3ê°œë¥¼ ê³¨ë¼ì£¼ì„¸ìš”. [ì‚¬ìš©ì ì •ë³´] - ë ˆë²¨: {level} - ìµœê·¼ ê´€ì‹¬ì‚¬: {chat_history} [í›„ë³´ ë‰´ìŠ¤ ëª©ë¡ (ì œëª©ê³¼ ë³¸ë¬¸)] {candidate_contents} [ìš”ì²­] ê°€ì¥ ì í•©í•œ ìµœì¢… ê¸°ì‚¬ 3ê°œì˜ ë²ˆí˜¸('ê¸°ì‚¬ #')ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”. ì˜ˆì‹œ: {{"final_indices": [2, 5, 1]}}""")
    model = ChatOpenAI(model="gpt-4o", temperature=0)
    parser = JsonOutputParser()
    chain = prompt | model | parser
    try:
        response = chain.invoke({"level": user_profile['level'], "chat_history": ", ".join(user_profile['chat_history']), "candidate_contents": formatted_candidates})
        final_indices = response['final_indices']
        final_news = [candidate_news[i-1] for i in final_indices if 0 < i <= len(candidate_news)]
        print(f"âœ… 2ë‹¨ê³„ ì„ ë³„ ì™„ë£Œ. ìµœì¢… ë‰´ìŠ¤ 3ê±´ í™•ì •.")
        return final_news
    except Exception as e:
        print(f"ğŸ”´ 2ë‹¨ê³„ AI ì„ ë³„ ì‹¤íŒ¨: {e}")
        return candidate_news[:3]
