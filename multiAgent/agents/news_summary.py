"""
news_summary.py â€” ë‰´ìŠ¤ ìš”ì•½ ì—ì´ì „íŠ¸ (LangChain + FewShot + Personalization)
"""
from typing import List, Dict, Any, Optional
import re, json, time

from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage

# ============================================================
# ğŸ”§ ë””ë²„ê·¸ ì„¤ì •
# ============================================================
DEBUG = True

def dprint(*args, **kwargs):
    """ë””ë²„ê·¸ ëª¨ë“œì¼ ë•Œë§Œ ì¶œë ¥"""
    if DEBUG:
        print("[DBG news_summary]", *args, **kwargs)

# ---------------------------
# 0) ì•ˆì „ ì¥ì¹˜: ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ ì •ì œ + ì œì–´ë¬¸ì ì œê±°
# ---------------------------
def _strip_ctrl(text: str) -> str:
    if not text:
        return ""
    return re.sub(r"[\x00-\x08\x0b\x0c\x0e-\x1f]", " ", str(text))

def sanitize_articles(items: List[Any]) -> List[Dict]:
    safe = []
    for x in items:
        if isinstance(x, dict):
            safe.append({
                "title": _strip_ctrl(x.get("title", "")),
                "url": _strip_ctrl(x.get("url", "")),
                "content": _strip_ctrl(x.get("content", "")),
            })
    return safe

SAFE_MAX_CHARS = 4000  # GPT-4o-mini í† í° í•œë„ ê³ ë ¤

# ---------------------------
# 1) ë ˆë²¨ë³„ í“¨ìƒ· (ìŠ¤í‚¤ë§ˆ ìœ ì§€, ê°œì¸í™” ë¬¸êµ¬ ê°•í™”)
# ---------------------------
FEW_SHOT_EXAMPLES = {
    "ì”¨ì•—": [{
        "input": "ë¯¸ ì—°ì¤€ì´ ê¸°ì¤€ê¸ˆë¦¬ë¥¼ ë™ê²°í–ˆë‹¤ëŠ” ë‰´ìŠ¤ ë³¸ë¬¸",
        "output": {
            "summary_5sentences": (
                "ë¯¸êµ­ì˜ ê¸°ì¤€ê¸ˆë¦¬ê°€ ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ë©´ì„œ ë‹¹ì¥ ëŒ€ì¶œ ì´ìë‚˜ ì˜ˆê¸ˆ ì´ìê°€ ê°‘ìê¸° í¬ê²Œ ë°”ë€Œì§€ëŠ” ì•Šê²Œ ë˜ì—ˆì–´ìš”. "
                "ì§‘ì„ ì‚¬ë ¤ê³  í•˜ê±°ë‚˜ í•™ìê¸ˆÂ·ìƒí™œë¹„ ëŒ€ì¶œì„ ì“°ëŠ” ì‚¬ëŒë“¤ì€ í•œìˆ¨ ëŒë¦´ ìˆ˜ ìˆì§€ë§Œ, ì•ìœ¼ë¡œ ë¬¼ê°€ì™€ ì¼ìë¦¬ ìƒí™©ì„ ë³´ë©° ë‹¤ì‹œ ê²°ì •í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì€ ê¸°ì–µí•´ì•¼ í•´ìš”. "
                "ë¯¸êµ­ ê¸ˆë¦¬ê°€ ê·¸ëŒ€ë¡œë¼ì„œ ì›Â·ë‹¬ëŸ¬ í™˜ìœ¨ê³¼ í•´ì™¸ ìê¸ˆ íë¦„ì—ë„ í° ì¶©ê²©ì€ ì—†ì§€ë§Œ, ë‰´ìŠ¤ì— ë”°ë¼ ì„œì„œíˆ ì›€ì§ì¼ ìˆ˜ ìˆì–´ìš”. "
                "ìš°ë¦¬ë‚˜ë¼ì—ë„ ê°„ì ‘ì ì¸ ì˜í–¥ì´ ì˜¤ê¸° ë•Œë¬¸ì—, ë‰´ìŠ¤ë¥¼ ë³¼ ë•Œ 'ê¸ˆë¦¬Â·í™˜ìœ¨Â·ë¬¼ê°€'ê°€ ê°™ì´ ì›€ì§ì¸ë‹¤ëŠ” ì •ë„ë§Œ ì•Œì•„ë‘ë©´ ì¶©ë¶„í•´ìš”. "
                "ì§€ê¸ˆì€ ê²ë¨¹ê¸°ë³´ë‹¤, ì“¸ë°ì—†ëŠ” ì†Œë¹„ë¥¼ ì¡°ê¸ˆ ì¤„ì´ê³  ë‹¤ìŒ ê¸ˆë¦¬ ê²°ì • ì†Œì‹ì„ ì°¨ë¶„íˆ ì±™ê²¨ë³´ëŠ” ì—°ìŠµì„ í•˜ë©´ ì¢‹ì•„ìš”."
            ),
            "key_points": [
                "ê¸°ì¤€ê¸ˆë¦¬ ë™ê²°ë¡œ ë‹¨ê¸° ì´ì ë¶€ë‹´ ë³€í™” ì œí•œ",
                "í–¥í›„ ê²°ì •ì€ ë¬¼ê°€Â·ê³ ìš© ì§€í‘œì— ë”°ë¼ ìœ ë™ì ",
                "êµ­ë‚´ì—ëŠ” í™˜ìœ¨Â·ìê¸ˆ íë¦„ì„ í†µí•´ ê°„ì ‘ ì˜í–¥"
            ],
            "metrics": [
                {"name": "Fed Funds Rate", "value": "5.25~5.50%", "period": "ì´ë²ˆ íšŒì˜"},
                {"name": "CPI ìƒìŠ¹ë¥ ", "value": "ê¸°ì‚¬ ê¸°ì¤€ ìˆ˜ì¹˜ ì‚¬ìš©", "period": "ìµœê·¼ ë°œí‘œì¹˜"}
            ],
            "term_candidates": ["ê¸°ì¤€ê¸ˆë¦¬", "í†µí™”ì •ì±…", "ë¬¼ê°€", "í™˜ìœ¨"]
        }
    }],
    "ìƒˆì‹¹": [{
        "input": "ì›/ë‹¬ëŸ¬ í™˜ìœ¨ì´ 1,400ì›ì„ ëŒíŒŒí–ˆë‹¤ëŠ” ë‰´ìŠ¤ ë³¸ë¬¸",
        "output": {
            "summary_5sentences": (
                "ì›/ë‹¬ëŸ¬ í™˜ìœ¨ì´ 1,400ì›ì„ ë„˜ì–´ì„œë©´ì„œ ìˆ˜ì… ë¬¼ê°€ì™€ í•´ì™¸ ê²°ì œ ë¹„ìš©ì´ ì „ë°˜ì ìœ¼ë¡œ ì˜¬ë¼ê°ˆ ìˆ˜ ìˆëŠ” êµ¬ê°„ì— ë“¤ì–´ì„°ìŠµë‹ˆë‹¤. "
                "ë‹¬ëŸ¬ë¡œ ê²°ì œí•˜ëŠ” ìœ í•™ë¹„, ìŠ¤íŠ¸ë¦¬ë°Â·ì†Œí”„íŠ¸ì›¨ì–´ êµ¬ë…ë£Œ, í•´ì™¸ ì§êµ¬ ë¹„ìš© ë“±ì´ ì´ì „ë³´ë‹¤ ë¹„ì‹¸ì§ˆ ìˆ˜ ìˆì–´ ì§€ì¶œ ê³„íšì„ ë‹¤ì‹œ ì ê²€í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. "
                "ê¸°ì—… ì…ì¥ì—ì„œëŠ” ì›ìì¬Â·ì—ë„ˆì§€ ìˆ˜ì… ë‹¨ê°€ê°€ ë†’ì•„ì ¸ ì œí’ˆ ê°€ê²© ì¸ìƒ ì••ë ¥ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆê³ , ì´ëŠ” ì‹œê°„ì´ ì§€ë‚˜ ì†Œë¹„ì ë¬¼ê°€ì—ë„ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                "ë‹¤ë§Œ í™˜ìœ¨ì€ ê¸€ë¡œë²Œ ê²½ê¸°, ê¸ˆë¦¬ ì°¨ì´, ìœ„í—˜ íšŒí”¼ ì‹¬ë¦¬ ë³€í™”ì— ë”°ë¼ ë˜ëŒë¦¼ì´ ë‚˜ì˜¬ ìˆ˜ ìˆì–´ ë‹¨ê¸° ê¸‰ë“±ë§Œ ë³´ê³  ì„±ê¸‰íˆ í™˜ì „ì´ë‚˜ íˆ¬ìë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì€ ë°”ëŒì§í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                "ì•ìœ¼ë¡œëŠ” í™˜ìœ¨ íë¦„ê³¼ í•¨ê»˜ ë¬¼ê°€, ë¯¸êµ­Â·í•œêµ­ ê¸ˆë¦¬ ë°©í–¥ì„ í•¨ê»˜ ë³´ë©´ì„œ í° ì§€ì¶œ ì‹œê¸°ì™€ ë¶„í•  í™˜ì „ ì „ëµì„ ìƒê°í•´ ë³´ëŠ” ê²ƒì´ í˜„ì‹¤ì ì¸ ëŒ€ì‘ì…ë‹ˆë‹¤."
            ),
            "key_points": [
                "í™˜ìœ¨ 1,400ì› ëŒíŒŒë¡œ ìˆ˜ì…Â·í•´ì™¸ê²°ì œ ë¹„ìš© ë¶€ë‹´ í™•ëŒ€",
                "ê¸°ì—… ì›ê°€ ìƒìŠ¹ì´ ì†Œë¹„ì ë¬¼ê°€ë¡œ ì „ê°€ë  ê°€ëŠ¥ì„± ì¡´ì¬",
                "ë‹¨ê¸° ê¸‰ë“±ì— ê³¼ë„ ë°˜ì‘ë³´ë‹¤ ì§€í‘œì™€ íë¦„ì„ í•¨ê»˜ ê´€ì°° í•„ìš”"
            ],
            "metrics": [
                {"name": "USD/KRW", "value": "1,400ì› ìƒíšŒ", "period": "ë‹¹ì¼"},
                {"name": "WTI/ì›ìì¬ ê°€ê²©", "value": "ê¸°ì‚¬ ë‚´ ìˆ˜ì¹˜ ì°¸ì¡°", "period": "ë™ì¼ ê¸°ê°„"}
            ],
            "term_candidates": ["í™˜ìœ¨", "ìˆ˜ì…ë¬¼ê°€", "ë¬´ì—­ìˆ˜ì§€", "ìœ„í—˜íšŒí”¼"]
        }
    }],

    "ë‚˜ë¬´": [{
        "input": "ë°˜ë„ì²´ ì—…í™© ê°œì„  ê¸°ëŒ€ê°ìœ¼ë¡œ ì½”ìŠ¤í”¼ê°€ ìƒìŠ¹í–ˆë‹¤ëŠ” ë‰´ìŠ¤ ë³¸ë¬¸",
        "output": {
            "summary_sentences": (
                "ë°˜ë„ì²´ ì—…í™© íšŒë³µ ê¸°ëŒ€ê°ê³¼ ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ì„¸ì— í˜ì…ì–´ ì½”ìŠ¤í”¼ê°€ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤. "
                "ìµœê·¼ ê¸°ì—… ì´ìµ ì „ë§ì¹˜ë„ ë¹ ë¥´ê²Œ ì˜¤ë¥´ê³  ìˆìŠµë‹ˆë‹¤. "
                "í•˜ì§€ë§Œ ì£¼ê°€ê°€ ì‹¤ì  ê°œì„  ì†ë„ë³´ë‹¤ ë„ˆë¬´ ì•ì„œê°„ ê²ƒì€ ì•„ë‹Œì§€ ë°¸ë¥˜ì—ì´ì…˜ ë¶€ë‹´ì„ ì ê²€í•  ë•Œì…ë‹ˆë‹¤. "
                "ë‹¨ê¸°ì ìœ¼ë¡œ ê±°ë˜ëŒ€ê¸ˆì´ ê¸‰ì¦í•˜ëŠ” ë“± ì¼ë¶€ ê³¼ì—´ ì‹ í˜¸ë„ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤. "
                "ì´ì— ë³€ë™ì„± ê´€ë¦¬ë¥¼ ìœ„í•´ ë¶„í•  ë§¤ë„ ë“±ì˜ ì „ëµì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                "íŠ¹íˆ ë°˜ë„ì²´ ë¹„ì¤‘ì´ ë†’ì€ í¬íŠ¸í´ë¦¬ì˜¤ëŠ” ê¸€ë¡œë²Œ IT ìˆ˜ìš” ê°™ì€ ê±°ì‹œ ë³€ìˆ˜ë¥¼ í•¨ê»˜ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•©ë‹ˆë‹¤. "
                "ì´ë²ˆ ìƒìŠ¹ì„ ê³„ê¸°ë¡œ ë‹¨ê¸° ëª¨ë©˜í…€ê³¼ í€ë”ë©˜í„¸ì˜ ê´´ë¦¬ë¥¼ ë¶„ì„í•˜ëŠ” ìì„¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            ),
            "key_points": [
                "ë°˜ë„ì²´ ì‹¤ì  ìƒí–¥ê³¼ ì™¸êµ­ì¸ ìˆ˜ê¸‰ì´ ì§€ìˆ˜ ìƒìŠ¹ì„ ê²¬ì¸",
                "ë°¸ë¥˜ì—ì´ì…˜ê³¼ ì´ìµ ì „ë§ì˜ ì •í•©ì„± ì ê²€ í•„ìš”",
                "ê³¼ì—´ ì‹ í˜¸ êµ¬ê°„ì—ì„œ ë¶„í•  ë§¤ë§¤ì™€ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì „ëµ ìš”êµ¬"
            ],
            "metrics": [
                {"name": "KOSPI", "value": "+1% ë‚´ì™¸ ìƒìŠ¹", "period": "ë‹¹ì¼"},
                {"name": "ë°˜ë„ì²´ ì—…ì¢… ì§€ìˆ˜", "value": "ìƒìŠ¹", "period": "ë™ì¼ ê¸°ê°„"}
            ],
            "term_candidates": ["ë°¸ë¥˜ì—ì´ì…˜", "ìˆœë§¤ìˆ˜", "ëª¨ë©˜í…€", "ì´ìµì¶”ì •", "ë¦¬ìŠ¤í¬ê´€ë¦¬"]
        }
    }],

    "ìˆ²": [{
        "input": "ì¬ì •ì§€ì¶œ í™•ëŒ€ì™€ ê¸´ì¶•ì  í†µí™”ì •ì±… ë³‘í–‰ì— ëŒ€í•œ ë¶„ì„ ê¸°ì‚¬ ë³¸ë¬¸",
        "output": {
            "summary_sentences": (
                "í™•ì¥ ì¬ì •ê³¼ ê¸´ì¶• í†µí™”ë¼ëŠ” ìƒì¶©í•˜ëŠ” ì •ì±… ì¡°í•©ì´ ì‹œì¥ ë¶ˆí™•ì‹¤ì„±ì„ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤. "
                "êµ­ì±„ ë°œí–‰ í™•ëŒ€ì™€ ë†’ì€ ê¸°ì¤€ê¸ˆë¦¬ëŠ” ì¥ê¸°ë¬¼ ê¸ˆë¦¬ì— êµ¬ì¡°ì ì¸ ìƒë°© ì••ë ¥ìœ¼ë¡œ ì‘ìš©í•©ë‹ˆë‹¤. "
                "ì´ëŠ” ê¸°ê°„ í”„ë¦¬ë¯¸ì—„ì˜ ì¬í‰ê°€ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                "ê²°ê³¼ì ìœ¼ë¡œ ìˆ˜ìµë¥  ê³¡ì„ ì˜ í˜•íƒœ ë˜í•œ ë³€í™”í•  ê°€ëŠ¥ì„±ì´ ì»¤ì¡ŒìŠµë‹ˆë‹¤. "
                "ì´ì— ê¸°ê´€ íˆ¬ììë“¤ì€ ë“€ë ˆì´ì…˜ ë…¸ì¶œê³¼ ì»¤ë¸Œ í¬ì§€ì…”ë‹ì„ ë”ìš± ì„¸ì‹¬í•˜ê²Œ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤. "
                "ë§Œì•½ ì¬ì • ê±´ì „ì„± ìš°ë ¤ê°€ ì»¤ì§€ë©´ ì™¸êµ­ì¸ ìê¸ˆ ìœ ì¶œê³¼ í†µí™”ê°€ì¹˜ í•˜ë½ì´ ë™ë°˜ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                "ë”°ë¼ì„œ ì •ì±… ì¡°í•©ì˜ ì‹ ë¢°ë„ë¥¼ í•´ì„í•˜ë©° ìì‚° ë¹„ì¤‘ì„ ì¡°ì ˆí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
            ),
            "key_points": [
                "ì¬ì • í™•ëŒ€ì™€ í†µí™” ê¸´ì¶• ë³‘í–‰ì´ ì¥ê¸° ê¸ˆë¦¬ ë° ì»¤ë¸Œ êµ¬ì¡°ì— ì˜í–¥",
                "êµ­ì±„ ê³µê¸‰ í™•ëŒ€ì™€ ê¸°ê°„í”„ë¦¬ë¯¸ì—„ ì¬í‰ê°€ ë¦¬ìŠ¤í¬ ìƒì¡´",
                "ì •ì±… ì‹ ë¢° ì•½í™” ì‹œ ì™¸êµ­ì¸ ìˆ˜ê¸‰Â·í†µí™”ê°€ì¹˜ì— ì—°ì‡„ì  íŒŒê¸‰ ê°€ëŠ¥"
            ],
            "metrics": [
                {"name": "10Y-2Y ìŠ¤í”„ë ˆë“œ", "value": "ê¸°ì‚¬ ê¸°ì¤€ ìˆ˜ì¹˜ ì‚¬ìš©", "period": "ìµœê·¼"},
                {"name": "êµ­ì±„ ë°œí–‰ ê·œëª¨", "value": "ì¦ê°€", "period": "ì˜ˆì‚°/ë°œí–‰ ê³„íš"}
            ],
            "term_candidates": ["ì¬ì •ì •ì±…", "í†µí™”ì •ì±…", "ìˆ˜ìµë¥ ê³¡ì„ ", "ê¸°ê°„í”„ë¦¬ë¯¸ì—„", "ë“€ë ˆì´ì…˜", "í¬ë ˆë”§ìŠ¤í”„ë ˆë“œ"]
        }
    }],
}

# ---------------------------
# 2) í”„ë¡¬í”„íŠ¸ ë¹Œë”
# ---------------------------
def build_summary_prompt(level: str, user_profile: Dict = None) -> ChatPromptTemplate:
    level = level if level in FEW_SHOT_EXAMPLES else "ìƒˆì‹¹"
    
    # ë ˆë²¨ë³„ ì„¤ì •
    cfg = {
        "ì”¨ì•—": {
            "sent_avg": "25~30", "sent_max": 30,
            "jargon_max": 0, "tone": "ì¼ìƒì–´ ìœ„ì£¼, í‰ì´Â·ì§ì„¤",
            "personalize_rules": ["ìœ ì¹˜ì›ìƒì´ ì•Œì•„ ë“¤ì„ ìˆ˜ ìˆê²Œ ìš”ì•½í•˜ë¼."]
        },
        "ìƒˆì‹¹": {
            "sent_avg": "35~40", "sent_max": 40,
            "jargon_max": 1, "tone": "ê°„ê²°Â·ì‹¤ìš©, í•„ìš”ì‹œ ì‰¬ìš´ ê´„í˜¸ í’€ì´",
            "personalize_rules": ["ì´ˆë“±í•™ìƒì´ ì•Œì•„ ë“¤ì„ ìˆ˜ ìˆê²Œ ìš”ì•½í•˜ë¼."]
        },
        "ë‚˜ë¬´": {
            "sent_avg": "45~50", "sent_max": 50,
            "jargon_max": 3, "tone": "ì‹œì¥Â·ìˆ˜ê¸‰ ìš©ì–´ í—ˆìš©, ê³¼ì‰ì „ë¬¸ì–´ ê¸ˆì§€",
            "personalize_rules": ["ê²½ì œí•™ì„ ì „ê³µí•œ í•™ë¶€ìƒì´ ì•Œì•„ ë“¤ì„ ìˆ˜ ìˆê²Œ ìš”ì•½í•˜ë¼."]
        },
        "ìˆ²": {
            "sent_avg": "55~60", "sent_max": 60,
            "jargon_max": 5, "tone": "ì •ì±…Â·ì»¤ë¸ŒÂ·í”„ë¦¬ë¯¸ì—„ ë“± ê³ ê¸‰ ìš©ì–´ í—ˆìš©",
            "personalize_rules": ["ê²½ì œí•™ ë°•ì‚¬ í˜¹ì€ êµìˆ˜ê°€ ì•Œì•„ ë“¤ì„ ìˆ˜ ìˆê²Œ ìš”ì•½í•˜ë¼."]
        }
    }.get(level, { 
        "sent_avg": "50", "sent_max": 50, "jargon_max": 2, "tone": "ì¹œì ˆí•¨", "personalize_rules": ["ì‰½ê²Œ ì„¤ëª…í•˜ë¼"]
    })

    up = user_profile or {}
    interests = ", ".join(up.get("interests", [])) or "ì¼ë°˜"
    
    parser = JsonOutputParser()
    format_instructions = parser.get_format_instructions()

    system_tmpl = (
        "ë‹¹ì‹ ì€ ê²½ì œ ë‰´ìŠ¤ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µí•˜ê³ , ì‚¬ì‹¤ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì •í•˜ì§€ ë§ˆì„¸ìš”.\n"
        "ì˜¤ì§ JSON í•˜ë‚˜ë§Œ ë°˜í™˜í•˜ì„¸ìš”. ìŠ¤í‚¤ë§ˆëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n"
        f"{format_instructions}\n"
        "- summary_5sentences: 5ë¬¸ì¥ í•µì‹¬ ìš”ì•½(ë¬¸ì¥ ìˆ˜ ì •í™•íˆ 5ê°œ).\n"
        "- ** summary_len: ê¸€ì ìˆ˜ 500 ë‚´ì™¸ë¡œ í•µì‹¬ ìš”ì•½ ** (ì •í™•í•˜ê²Œ 500ì ë‚´ì™¸)"
        "- key_points: ë¶ˆë¦¿ 3ê°œ(ê°„ê²°, ì¤‘ë³µ ê¸ˆì§€).\n"
        "- metrics: ë³¸ë¬¸ì— ì‹¤ì¬í•˜ëŠ” ìˆ˜ì¹˜Â·ì§€í‘œë§Œ í¬í•¨(ì´ë¦„/ê°’/ê¸°ê°„ í•„ìˆ˜, ì—†ëŠ” ê²½ìš° ë¹ˆ ë°°ì—´).\n"
        "- term_candidates: ë…ìê°€ ëª¨ë¥¼ ë²•í•œ ê²½ì œ ìš©ì–´ 2~10ê°œ(ê¸°ì‚¬ ë§¥ë½ ë‚´ì—ì„œë§Œ).\n"
        f"- ë‚œì´ë„Â·ê°€ë…ì„± ëª©í‘œ(KReaD): í‰ê·  ë¬¸ì¥ ê¸¸ì´ {cfg['sent_avg']} ë‹¨ì–´, ìµœëŒ€ {cfg['sent_max']} ë‹¨ì–´/ë¬¸ì¥, "
        f"ì „ë¬¸ìš©ì–´ ìƒí•œ {cfg['jargon_max']}ê°œ, í†¤: {cfg['tone']}.\n"
        "- ê°œì¸í™”: ì•„ë˜ ì‚¬ìš©ì ì •ë³´ë¥¼ ë¬¸ì¥ì— â€˜ìì—°ìŠ¤ëŸ½ê²Œâ€™ ë…¹ì—¬ ì¨ì„œ ì‹¤ì œ í–‰ë™ íŒë‹¨ì— ë„ì›€ì´ ë˜ê²Œ í•˜ì„¸ìš”.\n"
        f"  Â· ê´€ì‹¬ì‚¬: {interests}\n"
        f"  Â· ë ˆë²¨: {level}\n"
        "- ê°œì¸í™” ë°˜ì˜ ê·œì¹™(ë ˆë²¨ë³„ í•„ìˆ˜ í¬í•¨):\n"
        f"  1) {cfg['personalize_rules'][0]}\n"
    )

    system = ChatPromptTemplate.from_messages([("system", system_tmpl)])
    
    fewshot = FewShotChatMessagePromptTemplate(
        example_prompt=ChatPromptTemplate.from_messages([
            ("human", "{input}"),
            ("ai", "{output}")
        ]),
        examples=FEW_SHOT_EXAMPLES[level],
    )

    user_tmpl = ChatPromptTemplate.from_messages([
        ("human",
         "ë‹¤ìŒ ê¸°ì‚¬ë¥¼ ìš”ì•½í•˜ì„¸ìš”.\n"
         "ì œëª©: {title}\n"
         "URL: {url}\n"
         "ë³¸ë¬¸:\n{content}\n\n"
         "ì œì•½:\n"
         "1) ë³¸ë¬¸ì— ì—†ëŠ” ìˆ˜ì¹˜Â·ì‚¬ì‹¤ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.\n"
         "2) summary_sentencesëŠ” ì •í™•íˆ 5ë¬¸ì¥, ì´ 450~550ì ë‚´ì™¸ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n"
         "3) JSON ì™¸ì˜ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ë¥¼ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.")
    ])

    return system + fewshot + user_tmpl


# ---------------------------
# 3) ë‹¨ì¼ ê¸°ì‚¬ ìš”ì•½ (JSON íŒŒì‹± + ì¬ì‹œë„)
# ---------------------------
def _json_loose_parse(s: str) -> Dict:
    try:
        return json.loads(s)
    except Exception:
        s2 = s.strip()
        s2 = re.sub(r"^```json\s*|\s*```$", "", s2, flags=re.IGNORECASE | re.DOTALL)
        try:
            return json.loads(s2)
        except Exception:
            return {}

def summarize_one(article: Dict, level: str, user_profile: Dict) -> Dict:
    model = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.2,
        timeout=60,
        model_kwargs={"response_format": {"type": "json_object"}},
    )
    parser = JsonOutputParser()
    prompt = build_summary_prompt(level, user_profile)

    title = article.get("title", "")
    url = article.get("url", "")
    raw_content = (article.get("content", "") or "")
    content = _strip_ctrl(raw_content)[:SAFE_MAX_CHARS]

    if not content.strip():
        dprint(f"Skip empty content for: {title}")
        return {
            "title": title, "url": url, "level": level,
            "summary_5sentences": "ë³¸ë¬¸ì´ ë¹„ì–´ ìˆì–´ ìš”ì•½ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "key_points": ["ë³¸ë¬¸ ëˆ„ë½"], "metrics": [], "term_candidates": [],
            "_error": "empty_content"
        }

    last_err = None
    for attempt in range(3):
        try:
            if attempt > 0:
                dprint(f"Retry summary ({attempt+1}/3) for: {title[:10]}...")
            
            chain = prompt | model
            raw = chain.invoke({"title": title, "url": url, "content": content})
            text = raw.content if hasattr(raw, "content") else str(raw)
            
            data = _json_loose_parse(text)
            if not data:
                data = parser.parse(text)

            # ìµœì†Œ í•„ë“œ ë³´ì •
            data.setdefault("summary_5sentences", "")
            data.setdefault("key_points", [])
            data.setdefault("metrics", [])
            data.setdefault("term_candidates", [])
            
            # ì„±ê³µ ì‹œ ë””ë²„ê·¸ ë¡œê·¸
            dprint(f"Summary OK: {title[:10]}... (len={len(data['summary_5sentences'])})")
            return {"title": title, "url": url, "level": level, **data}
            
        except Exception as e:
            last_err = str(e)
            dprint(f"Summary failed attempt {attempt+1}: {e}")
            time.sleep(0.5 * (attempt + 1))

    dprint(f"Give up summarizing: {title[:10]}...")
    return {
        "title": title, "url": url, "level": level,
        "summary_5sentences": f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ({last_err})",
        "key_points": ["ì²˜ë¦¬ ì‹¤íŒ¨"], "metrics": [], "term_candidates": [], "_error": str(last_err)
    }


# ---------------------------
# 4) ë©”ì¸ í•¸ë“¤ëŸ¬ (Chatbot)
# ---------------------------
def handle(text: str, profile: Optional[Dict[str, Any]] = None, state: Optional[Dict[str, Any]] = None) -> AIMessage:
    dprint("[handle] ENTER news_summary_node")
    
    ctx = (state or {}).get("context", {})
    profile = profile or (state or {}).get("profile", {}) or {}
    
    if isinstance(profile, dict):
        # ë”•ì…”ë„ˆë¦¬ë¡œ ë„˜ì–´ì˜¨ ê²½ìš° (í˜„ì¬ Django í™˜ê²½)
        level = profile.get("grade", "ìƒˆì‹¹")
    else:
        # ê°ì²´ë¡œ ë„˜ì–´ì˜¨ ê²½ìš° (ê¸°ì¡´ í™˜ê²½ í˜¸í™˜)
        level = getattr(profile, "grade", "ìƒˆì‹¹")
        
    articles = ctx.get("selected_articles", [])
    
    dprint(f"Profile Level: {level}, Articles to summarize: {len(articles)}")
    
    if not articles:
        dprint("No articles found in context.")
        return AIMessage(content="[news_summary] ìš”ì•½í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ ì£¼ì„¸ìš”.")

    sanitized = sanitize_articles(articles)
    summaries = []
    
    for i, art in enumerate(sanitized, 1):
        dprint(f"[{i}/{len(sanitized)}] Summarizing: {art.get('title','Untitled')}")
        res = summarize_one(art, level, profile)
        summaries.append(res)

    # ê²°ê³¼ë¥¼ State Contextì— ì €ì¥
    ctx["summaries"] = summaries
    dprint(f"Saved {len(summaries)} summaries to context['summaries']")

    # ì±—ë´‡ ì‘ë‹µ ìƒì„±
    msg_lines = [f"[news_summary] ì´ {len(summaries)}ê±´ì˜ ê¸°ì‚¬ë¥¼ ìš”ì•½í–ˆìŠµë‹ˆë‹¤.\n"]
    for i, s in enumerate(summaries, 1):
        title = s.get("title", "ë¬´ì œ")
        url = s.get("url", "") # âœ… URL ê°€ì ¸ì˜¤ê¸°
        summary = s.get("summary_5sentences", "")
        
        msg_lines.append(f"{i}. {title}")
        if url: # âœ… URLì´ ìˆìœ¼ë©´ ì¶œë ¥
            msg_lines.append(f"   ğŸ”— {url}")
        msg_lines.append(f"   [ìš”ì•½] {summary}\n") 
    
    return AIMessage(content="\n".join(msg_lines))


# ============================================================
# 5. [Batch] ë°ì¼ë¦¬ íŒŒì´í”„ë¼ì¸ìš© í•¨ìˆ˜
# ============================================================
def build_daily_summaries(state: Dict[str, Any], profile: Dict) -> List[Dict]:
    """
    ë§¤ì¼ ì•„ì¹¨ ì‹¤í–‰ë˜ëŠ” ë°°ì¹˜ ì‘ì—…ìš© í•¨ìˆ˜.
    state['context']['daily_pool'] (ë˜ëŠ” selected_articles)ì˜ ê¸°ì‚¬ë¥¼ ì½ì–´ 
    ì¼ê´„ ìš”ì•½í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•¨.
    """
    ctx = state.get("context", {})
    level = profile.get("level", "ìƒˆì‹¹")
    
    # 1. ìš”ì•½ ëŒ€ìƒ ì‹ë³„
    # ë°°ì¹˜ ëª¨ë“œì—ì„œëŠ” ë³´í†µ 'daily_pool'(news_findì˜ ê²°ê³¼)ì„ ì‚¬ìš©
    # ì—†ìœ¼ë©´ selected_articles(í…ŒìŠ¤íŠ¸ìš©) í´ë°±
    source_articles = ctx.get("daily_pool") or ctx.get("selected_articles", [])
    
    dprint(f"[Batch] Starting daily summary for {len(source_articles)} articles (Level: {level})")
    
    if not source_articles:
        dprint("[Batch] No articles to summarize.")
        return []

    sanitized = sanitize_articles(source_articles)
    daily_summaries = []
    
    for i, art in enumerate(sanitized, 1):
        dprint(f"[Batch] Summarizing [{i}/{len(sanitized)}]: {art.get('title','Untitled')}")
        res = summarize_one(art, level, profile)
        daily_summaries.append(res)
        
    # ê²°ê³¼ ì €ì¥ (ë³´í†µ íŒŒì´í”„ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ stateì— í• ë‹¹í•˜ê² ì§€ë§Œ, ì—¬ê¸°ì„œë„ ë°˜í™˜)
    return daily_summaries