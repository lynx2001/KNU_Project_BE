from typing import List, Literal, Dict, Any
from pydantic import BaseModel
from langchain_openai import ChatOpenAI

# âœ… ì—¬ëŸ¬ ë‹¨ê³„ë¥¼ ìˆœì„œëŒ€ë¡œ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
class RouteDecision(BaseModel):
    intents: List[Literal["news_find","news_summary","term_explain","quiz","qa"]]

# âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • (í€´ì¦ˆ ìƒíƒœ ë°˜ì˜ ê·œì¹™ ì¶”ê°€)
SYSTEM_TEMPLATE = (
    "ë„ˆëŠ” ë‰´ìŠ¤ í•™ìŠµ íŠœí„° ì‹œìŠ¤í…œì˜ **ì˜ë„ ë¶„ë¥˜ì(Supervisor Router)** ì—­í• ì„ í•´. "
    "ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•´ì„œ ì–´ë–¤ ì‘ì—… ë‹¨ê³„ë“¤ì´ í•„ìš”í•œì§€ë¥¼ **ìˆœì„œëŒ€ë¡œ íŒë‹¨**í•´ì•¼ í•´. "

    "í˜„ì¬ ìƒíƒœ ì •ë³´:\n"
    "- í€´ì¦ˆ ì§„í–‰ ì¤‘ ì—¬ë¶€(is_quiz_active): {is_quiz_active}\n\n"

    "ê°€ëŠ¥í•œ ë‹¨ê³„(intent)ëŠ” ì•„ë˜ ë‹¤ì„¯ ê°€ì§€ì•¼:\n"
    "1ï¸âƒ£ qa â€” ì¼ë°˜ì ì¸ ì§ˆë¬¸ì´ë‚˜ ì‚¬ì‹¤ í™•ì¸, ë˜ëŠ” ë‹¨ìˆœ ì¸ì‚¬Â·ì¡ë‹´.\n"
    "2ï¸âƒ£ news_find â€” ë‰´ìŠ¤ ê²€ìƒ‰ ìš”ì²­.\n"
    "3ï¸âƒ£ news_summary â€” ë‰´ìŠ¤ ìš”ì•½ ìš”ì²­.\n"
    "4ï¸âƒ£ term_explain â€” ìš©ì–´ ì„¤ëª… ìš”ì²­.\n"
    "5ï¸âƒ£ quiz â€” í€´ì¦ˆ ìƒì„± ìš”ì²­ **ë˜ëŠ” í€´ì¦ˆ ì •ë‹µ ì œì¶œ**.\n\n"

    "â­â­ **ë¼ìš°íŒ… ìµœìš°ì„  ê·œì¹™** â­â­:\n"
    "ğŸ‘‰ ë§Œì•½ **is_quiz_active=True**ì´ê³ , ì‚¬ìš©ìê°€ ìˆ«ì('1', '2'...), ì•ŒíŒŒë²³('O', 'X'), ë˜ëŠ” ë‹¨ë‹µí˜• ì •ë‹µì„ ë§í–ˆë‹¤ë©´, "
    "ë‹¤ë¥¸ ìƒê° í•˜ì§€ ë§ê³  ë¬´ì¡°ê±´ **['quiz']** ë¡œ ë¶„ë¥˜í•´.\n"
    "   (ì˜ˆ: '1' -> ['quiz'], 'ì •ë‹µì€ O' -> ['quiz'])\n\n"

    "ê·¸ ì™¸ ì¼ë°˜ ê·œì¹™:\n"
    " - 'ì‚¼ì„±ì „ì ì£¼ê°€ ì•Œë ¤ì£¼ê³  ê´€ë ¨ ê¸°ì‚¬ ìš”ì•½í•´ì¤˜' â†’ ['qa','news_find','news_summary']\n"
    " - 'ìµœê·¼ ê¸ˆë¦¬ ê¸°ì‚¬ ì°¾ì•„ì„œ í€´ì¦ˆ ë‚´ì¤˜' â†’ ['news_find','quiz']\n"
    " - 'ì•ˆë…•', 'ê³ ë§ˆì›Œ' â†’ ['qa']\n\n"

    "ë§Œì•½ ì‚¬ìš©ìì˜ ìš”ì²­ì´ ìœ„ ë‹¨ê³„ë“¤ì— ëª…í™•íˆ ë§ì§€ ì•ŠëŠ”ë‹¤ë©´ ê¸°ë³¸ì ìœ¼ë¡œ ['qa'] ë¡œ ë¶„ë¥˜í•´.\n"
    "í•­ìƒ JSON í˜•ì‹ìœ¼ë¡œ ì•„ë˜ì²˜ëŸ¼ë§Œ ëŒ€ë‹µí•´:\n"
    "{{ \"intents\": [ ...ë‹¨ê³„ë“¤... ] }}"
)


def classify_intent(user_text: str, context: Dict[str, Any] = {}) -> List[str]:
    print("[DBG router] IN:", repr(user_text))
    
    # âœ… Contextì—ì„œ í€´ì¦ˆ í™œì„±í™” ì—¬ë¶€ í™•ì¸
    is_quiz_active = bool(context.get("active_quiz"))
    if is_quiz_active:
        print(f"[DBG router] Quiz is ACTIVE. Prioritizing 'quiz' intent for answers.")

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0).with_structured_output(RouteDecision)
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ìƒíƒœ ì£¼ì…
    system_prompt = SYSTEM_TEMPLATE.format(is_quiz_active=str(is_quiz_active))
    
    out = llm.invoke([
        {"role":"system","content": system_prompt},
        {"role":"user","content": user_text or ""},
    ])
    
    intents = getattr(out, "intents", None)
    if intents is None:
        intents = [getattr(out, "intent", "qa")]

    print("[DBG router] OUT intents =", intents)
    return intents